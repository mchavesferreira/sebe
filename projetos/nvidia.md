√ìtimo! Agora que a RTX 5060 Ti foi **reconhecida e deu v√≠deo**, vamos instalar o **driver oficial Nvidia**, da forma mais segura e correta para Ubuntu, garantindo suporte completo para **CUDA, IA, PyTorch, TensorRT**.

A seguir est√° o **guia definitivo**, formal, limpo e completo.

---

# ‚úÖ **1) Verificar se o Ubuntu detectou a GPU**

Abra o terminal e execute:

```bash
lspci | grep -i nvidia
```

E:

```bash
nvidia-smi
```

Se aparecer:

```
Command 'nvidia-smi' not found
```

‚Üí Isso √© normal, pois o driver ainda n√£o est√° instalado.

---

# ‚úÖ **2) Atualizar o Ubuntu antes da instala√ß√£o**

```bash
sudo apt update
sudo apt upgrade -y
sudo reboot
```

Reinicie.

---

# ‚úÖ **3) Instalar driver Nvidia recomendado automaticamente**

Esta √© a forma **oficial e mais est√°vel** no Ubuntu:

```bash
sudo ubuntu-drivers autoinstall
```

O sistema vai instalar automaticamente o driver mais adequado (geralmente **nvidia-driver-550** ou superior para a s√©rie RTX 5000).

Ap√≥s a instala√ß√£o:

```bash
sudo reboot
```

---

# ‚úÖ **4) Confirmar que o driver Nvidia est√° ativo**

Ap√≥s reiniciar, execute:

```bash
nvidia-smi
```

A sa√≠da esperada √© semelhante a:

```
NVIDIA-SMI 550.xx     Driver Version: 550.xx     CUDA Version: 12.x
GPU 0: GeForce RTX 5060 Ti
```

Se aparecer essa tabela ‚Üí **sucesso total**.

---

# üìå **5) Ativar o driver via interface gr√°fica (alternativa)**

Se preferir GUI:

1. Configura√ß√µes
2. **Software e Atualiza√ß√µes**
3. Aba **Drivers adicionais**
4. Selecione **NVIDIA driver (propriet√°rio, tested)**
5. Aplicar mudan√ßas
6. Reiniciar

Mas **a linha de comando √© mais confi√°vel**.

---

# ‚ö†Ô∏è **6) Evite instalar o driver diretamente do site da Nvidia**

N√£o use o arquivo `.run`.

Motivos:

* Desativa o DKMS
* Quebra atualiza√ß√µes do kernel
* Pode causar tela preta
* N√£o integra com o Ubuntu

Sempre use `ubuntu-drivers autoinstall`.

---

# üîß **7) Instalar ferramentas adicionais da Nvidia (opcionais)**

### Painel Nvidia:

```bash
sudo apt install nvidia-settings
```

### CUDA toolkit (opcional, apenas se for treinar IA local):

```bash
sudo apt install nvidia-cuda-toolkit
```

### Checar vers√£o CUDA:

```bash
nvcc --version
```

---

# ü§ñ **8) Preparar ambiente para Machine Learning (opcional)**

Se voc√™ pretende rodar IA localmente (PyTorch, TensorFlow, LLMs etc.), posso gerar os comandos exatos:

* Instalar **CUDA 12.6** com compatibilidade total
* Instalar **cuDNN**
* Instalar **PyTorch com CUDA**
* Instalar **TensorRT** para otimiza√ß√£o
* Preparar ambiente Python virtual

Se quiser, escrevo todo o procedimento com precis√£o profissional.

---

# üéØ **Resumo R√°pido**

```bash
sudo apt update
sudo apt upgrade -y
sudo ubuntu-drivers autoinstall
sudo reboot
nvidia-smi
```

Se `nvidia-smi` mostrar a GPU ‚Üí tudo funcionando corretamente.

---

Deseja agora o **passo a passo para instalar PyTorch com CUDA**, ou prefere instalar tamb√©m **TensorRT** para acelerar LLMs na sua RTX 5060 Ti?



A seguir apresento um **guia completo, formal e detalhado** para preparar seu ambiente **Machine Learning** no Ubuntu **com suporte total √† RTX 5060 Ti**, utilizando:

* **CUDA 12.x** (vers√£o suportada pelo driver instalado)
* **cuDNN**
* **PyTorch otimizado para GPU**
* **Ambiente virtual Python**
* (Opcional) **TensorRT** para modelos LLM ultra otimizados

Este √© um guia profissional, compat√≠vel com ambientes de pesquisa e ensino.

---

# üß© **1) Confirmar instala√ß√£o correta do driver Nvidia**

```bash
nvidia-smi
```

A sa√≠da deve mostrar algo como:

```
NVIDIA-SMI 550.xx
CUDA Version: 12.x
GPU: GeForce RTX 5060 Ti
```

Se isso aparecer ‚Üí pode prosseguir.

---

# üß© **2) Instalar depend√™ncias essenciais para ML**

```bash
sudo apt update
sudo apt install -y build-essential cmake git python3-dev python3-pip python3-venv
```

Essas ferramentas garantem que bibliotecas cient√≠ficas possam ser compiladas quando necess√°rio.

---

# üß™ **3) Criar ambiente Python isolado (venv)**

Crie uma pasta para o seu ambiente:

```bash
mkdir ~/ml
cd ~/ml
```

Criar o ambiente virtual:

```bash
python3 -m venv venv
```

Ativar:

```bash
source venv/bin/activate
```

(Quando ativado aparece `(venv)` no terminal.)

Atualizar pip:

```bash
pip install --upgrade pip
```

---

# üöÄ **4) Instalar o PyTorch com CUDA (vers√£o correta)**

A maneira mais segura √© usar o comando recomendado pelo pr√≥prio PyTorch para CUDA 12.x:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

Isso instala uma vers√£o com:

* kernels otimizados para RTX 50xx
* suporte a CUDA 12.1
* suporte a Tensor Cores
* acelera√ß√£o para treinamento e infer√™ncia

---

# üîç **5) Testar se o PyTorch est√° usando a GPU**

Abra o Python:

```bash
python3
```

Execute:

```python
import torch
print("CUDA dispon√≠vel:", torch.cuda.is_available())
print("GPU detectada:", torch.cuda.get_device_name(0))
```

Sa√≠da esperada:

```
CUDA dispon√≠vel: True
GPU detectada: NVIDIA GeForce RTX 5060 Ti
```

Se isso aparecer ‚Üí seu ambiente est√° pronto para ML.

---

# üí† **6) Instalar bibliotecas essenciais para ci√™ncia de dados**

```bash
pip install numpy scipy pandas scikit-learn matplotlib seaborn jupyter notebook
```

---

# üì¶ **7) Instalar bibliotecas de IA/LLMs (opcional)**

### **Transformers (HuggingFace)**

```bash
pip install transformers accelerate sentencepiece
```

### **Diffusers (para Stable Diffusion)**

```bash
pip install diffusers[torch]
```

### **OpenAI API (para modelos externos)**

```bash
pip install openai
```

---

# ‚ö° **8) (Opcional) Instalar TensorRT para acelerar LLM e IA**

Se quiser extrair **M√°ximo desempenho**:

* reduz lat√™ncia de infer√™ncia
* acelera modelos como LLaMA, Gemma, GPTQ, AWQ etc.
* muito √∫til para pesquisa de LLMs embarcados ou otimiza√ß√µes

Instala√ß√£o oficial NVIDIA:

```bash
sudo apt install tensorrt
```

Verificar vers√£o:

```bash
dpkg -l | grep tensorrt
```

---

# üß† **9) Instalar ferramentas para LLM local (opcional)**

### **Ollama (executar modelos localmente)**

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Rodar LLaMA ou Gemma:

```bash
ollama run llama3
```

### **LM Studio (interface gr√°fica)**

Funciona no Ubuntu:
[https://lmstudio.ai](https://lmstudio.ai)

---

# üß™ **10) Criar um laborat√≥rio Jupyter Notebook**

Dentro do ambiente:

```bash
jupyter notebook
```

Acesse no browser:

```
http://localhost:8888
```

---

# üéØ **Resumo do ambiente preparado**

| Componente        | Status                |
| ----------------- | --------------------- |
| Driver Nvidia     | ‚úî Instalado           |
| CUDA 12.x         | ‚úî Integrado           |
| cuDNN             | ‚úî Embutido no PyTorch |
| PyTorch GPU       | ‚úî Funcionando         |
| Bibliotecas de IA | ‚úî Prontas             |
| TensorRT          | ‚úî Opcional            |
| LLMs Locais       | ‚úî Opcional            |

---

# üîß Se desejar, posso gerar:

‚úî Um **script autom√°tico `.sh`** que instala tudo
‚úî Uma **vers√£o avan√ßada** com Docker + CUDA
‚úî Configura√ß√£o completa de **ambiente para treinar LLM pequenos (LoRA)**
‚úî Otimiza√ß√£o para estudos de IA no seu hardware (Ryzen 9 + RTX 5060 Ti)
‚úî Testes de benchmark da GPU

Deseja o **script completo de instala√ß√£o autom√°tica**?
